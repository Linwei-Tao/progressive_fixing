{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes a trained model and evaluates it on the following metrics:\n",
    "1. ECE pre and post temperature scaling\n",
    "2. MCE pre and post temperature scaling\n",
    "3. Test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "cwd = os.getcwd()\n",
    "\n",
    "module_path = \"/\".join(cwd.split('/')[0:-1])\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataloaders\n",
    "import Data.cifar10 as cifar10\n",
    "import Data.cifar100 as cifar100\n",
    "import Data.tiny_imagenet as tiny_imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import network architectures\n",
    "from Net.resnet import resnet50, resnet110\n",
    "from Net.wide_resnet import wide_resnet_cifar\n",
    "from Net.densenet import densenet121\n",
    "from Net.resnet_tiny_imagenet import resnet50 as resnet50_ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import metrics to compute\n",
    "from Metrics.metrics import expected_calibration_error\n",
    "from Metrics.metrics import maximum_calibration_error\n",
    "from Metrics.metrics import l2_error\n",
    "from Metrics.plots import reliability_plot, bin_strength_plot\n",
    "from Metrics.metrics import test_classification_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset params\n",
    "\n",
    "dataset_num_classes = {\n",
    "    'cifar10': 10,\n",
    "    'cifar100': 100,\n",
    "    'tiny_imagenet': 200\n",
    "}\n",
    "\n",
    "dataset_loader = {\n",
    "    'cifar10': cifar10,\n",
    "    'cifar100': cifar100,\n",
    "    'tiny_imagenet': tiny_imagenet\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping model name to model function\n",
    "models = {\n",
    "    'resnet50': resnet50,\n",
    "    'resnet50_ti': resnet50_ti,\n",
    "    'resnet110': resnet110,\n",
    "    'wide_resnet': wide_resnet_cifar,\n",
    "    'densenet121': densenet121,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if GPU is available\n",
    "cuda = False\n",
    "if (torch.cuda.is_available()):\n",
    "    cuda = True\n",
    "\n",
    "# Setting additional parameters\n",
    "torch.manual_seed(1)\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    data_aug = True\n",
    "    gpu = device == \"cuda\"\n",
    "    train_batch_size = 128\n",
    "    test_batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the dataset: \n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Taking input for the dataset\n",
    "print ('Enter the dataset: ')\n",
    "# dataset = input()\n",
    "dataset = \"cifar10\"\n",
    "num_classes = dataset_num_classes[dataset]\n",
    "\n",
    "if (dataset == 'tiny_imagenet'):\n",
    "    print ('Enter dataset root path: ')\n",
    "    dataset_root = input()\n",
    "    train_loader = dataset_loader[dataset].get_data_loader(\n",
    "        root=dataset_root,\n",
    "        split='train',\n",
    "        batch_size=args.train_batch_size,\n",
    "        pin_memory=args.gpu)\n",
    "\n",
    "    val_loader = dataset_loader[dataset].get_data_loader(\n",
    "        root=dataset_root,\n",
    "        split='val',\n",
    "        batch_size=args.test_batch_size,\n",
    "        pin_memory=args.gpu)\n",
    "\n",
    "    test_loader = dataset_loader[dataset].get_data_loader(\n",
    "        root=dataset_root,\n",
    "        split='val',\n",
    "        batch_size=args.test_batch_size,\n",
    "        pin_memory=args.gpu)\n",
    "else:\n",
    "    train_loader, val_loader = dataset_loader[dataset].get_train_valid_loader(\n",
    "        batch_size=args.train_batch_size,\n",
    "        augment=args.data_aug,\n",
    "        random_seed=1,\n",
    "        pin_memory=args.gpu\n",
    "    )\n",
    "\n",
    "    test_loader = dataset_loader[dataset].get_test_loader(\n",
    "        batch_size=args.test_batch_size,\n",
    "        pin_memory=args.gpu\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the model: \n",
      "Enter saved model name: \n",
      "Enter the number of bins: \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_4043364/3847763034.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[0mnet\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnum_classes\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnum_classes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtemp\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1.0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 18\u001B[0;31m \u001B[0mnet\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     19\u001B[0m \u001B[0mnet\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataParallel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnet\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice_ids\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[0mcudnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbenchmark\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/progressive_fixing/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36mcuda\u001B[0;34m(self, device)\u001B[0m\n\u001B[1;32m    678\u001B[0m             \u001B[0mModule\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    679\u001B[0m         \"\"\"\n\u001B[0;32m--> 680\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    681\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    682\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mxpu\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mT\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mUnion\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mT\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/progressive_fixing/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn)\u001B[0m\n\u001B[1;32m    568\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    569\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 570\u001B[0;31m             \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    571\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    572\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/progressive_fixing/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn)\u001B[0m\n\u001B[1;32m    591\u001B[0m             \u001B[0;31m# `with torch.no_grad():`\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    592\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 593\u001B[0;31m                 \u001B[0mparam_applied\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparam\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    594\u001B[0m             \u001B[0mshould_use_set_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparam\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparam_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    595\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mshould_use_set_data\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/progressive_fixing/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m<lambda>\u001B[0;34m(t)\u001B[0m\n\u001B[1;32m    678\u001B[0m             \u001B[0mModule\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    679\u001B[0m         \"\"\"\n\u001B[0;32m--> 680\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    681\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    682\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mxpu\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mT\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mUnion\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mT\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "# Taking input for the model\n",
    "print ('Enter the model: ')\n",
    "# model_name = input()\n",
    "model_name = \"resnet50\"\n",
    "print ('Enter saved model name: ')\n",
    "# saved_model_name = input()\n",
    "saved_model_name = \"/home/dylan/Desktop/progressive_fixing/weights/resnet50_focal_loss_adaptive_53_350.model\"\n",
    "\n",
    "model = models[model_name]\n",
    "\n",
    "# Evaluating the model at T = 1\n",
    "# Getting the number of bins\n",
    "print ('Enter the number of bins: ')\n",
    "# num_bins = int(input())\n",
    "num_bins = 15\n",
    "\n",
    "net = model(num_classes=num_classes, temp=1.0)\n",
    "net.cuda()\n",
    "net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
    "cudnn.benchmark = True\n",
    "net.load_state_dict(torch.load(str(saved_model_name)))\n",
    "\n",
    "conf_matrix, accuracy, labels, predictions, confidences = test_classification_net(net, test_loader, device)\n",
    "ece = expected_calibration_error(confidences, predictions, labels, num_bins=num_bins)\n",
    "mce = maximum_calibration_error(confidences, predictions, labels, num_bins=num_bins)\n",
    "\n",
    "# Printing the required evaluation metrics\n",
    "print (conf_matrix)\n",
    "print ('Test error: ' + str((1 - accuracy)))\n",
    "print ('ECE: ' + str(ece))\n",
    "print ('MCE: ' + str(mce))\n",
    "\n",
    "# Plotting the reliability plot\n",
    "reliability_plot(confidences, predictions, labels, num_bins=num_bins)\n",
    "bin_strength_plot(confidences, predictions, labels, num_bins=num_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluating the model at T = T_opt\n",
    "# Getting the number of bins\n",
    "print ('Enter the number of bins: ')\n",
    "# num_bins = int(input())\n",
    "num_bins = 15\n",
    "print ('Enter the optimal temperature: ')\n",
    "t_opt = 1.1\n",
    "\n",
    "net = model(num_classes=num_classes, temp=t_opt)\n",
    "net.cuda()\n",
    "# net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
    "cudnn.benchmark = True\n",
    "net.load_state_dict(torch.load(str(saved_model_name)))\n",
    "\n",
    "conf_matrix, accuracy, labels, predictions, confidences = test_classification_net(net, test_loader, device)\n",
    "ece = expected_calibration_error(confidences, predictions, labels, num_bins=num_bins)\n",
    "mce = maximum_calibration_error(confidences, predictions, labels, num_bins=num_bins)\n",
    "\n",
    "print (conf_matrix)\n",
    "print ('Test error: ' + str((1 - accuracy)))\n",
    "print ('ECE: ' + str(ece))\n",
    "print ('MCE: ' + str(mce))\n",
    "\n",
    "# Plotting the reliability plot\n",
    "reliability_plot(confidences, predictions, labels, num_bins=num_bins)\n",
    "bin_strength_plot(confidences, predictions, labels, num_bins=num_bins)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}